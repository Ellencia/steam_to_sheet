import requests
from bs4 import BeautifulSoup
import re
import os

# Base URL
BASE_URL = "https://monsnode.com/search.php?search=ikejyo%20yuri"

# User-Agent 헤더 추가 (웹사이트 차단 방지)
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36"
}

def get_redirect_links(base_url):
    """중간 링크 (redirect.php) 추출"""
    response = requests.get(base_url, headers=HEADERS)
    soup = BeautifulSoup(response.text, "html.parser")
    
    # 'redirect.php' 링크를 모두 수집
    redirect_links = []
    for a_tag in soup.find_all("a", href=True):
        if "redirect.php" in a_tag["href"]:
            redirect_links.append(a_tag["href"])
    
    return redirect_links

def get_video_url(redirect_url):
    """redirect 링크로부터 최종 영상 URL 얻기"""
    response = requests.get(redirect_url, headers=HEADERS, allow_redirects=True)
    # 최종 URL 반환
    return response.url

def download_video(video_url, save_dir="videos"):
    """영상 파일 다운로드"""
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    
    video_data = requests.get(video_url, headers=HEADERS).content
    filename = os.path.join(save_dir, video_url.split("/")[-1])  # 파일 이름 추출
    with open(filename, "wb") as video_file:
        video_file.write(video_data)
        print(f"Downloaded: {filename}")

def main():
    # Step 1: 중간 링크 추출
    redirect_links = get_redirect_links(BASE_URL)
    print(f"Found {len(redirect_links)} redirect links.")
    
    # Step 2: 각 중간 링크에서 최종 영상 URL 추출 및 다운로드
    for idx, redirect in enumerate(redirect_links, start=1):
        print(f"[{idx}] Fetching video URL from: {redirect}")
        try:
            video_url = get_video_url(redirect)
            print(f"Video URL: {video_url}")
            download_video(video_url)
        except Exception as e:
            print(f"Error processing {redirect}: {e}")

if __name__ == "__main__":
    main()
